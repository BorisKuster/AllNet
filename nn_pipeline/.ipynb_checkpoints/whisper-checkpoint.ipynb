{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9cf248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import ffmpeg\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e087a87",
   "metadata": {},
   "source": [
    "# Get input audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b5e8e",
   "metadata": {},
   "source": [
    "# Process audio and turn to TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56803f",
   "metadata": {},
   "source": [
    "# TEXT to SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8afcc197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 3, 'structVersion': 2, 'name': 'Logitech USB Headset: Audio (hw:1,0)', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.008, 'defaultLowOutputLatency': 0.008, 'defaultHighInputLatency': 0.032, 'defaultHighOutputLatency': 0.032, 'defaultSampleRate': 48000.0}\n"
     ]
    }
   ],
   "source": [
    "def pyaudio_get_output_device(searching_for = 'Logitech'):\n",
    "    # Input params\n",
    "    # Searching for - partial name of device which should be used. UPPER AND LOWER CASE MATTERS ! \n",
    "\n",
    "    # Find device\n",
    "    good_device_info = None\n",
    "    aud = pyaudio.PyAudio()\n",
    "    for i in range(0,15):\n",
    "        try:\n",
    "            info = aud.get_device_info_by_index(i)\n",
    "            #print(info['name'])\n",
    "            if searching_for in info['name']:\n",
    "                if info['maxOutputChannels']>=1:\n",
    "                    print(info)\n",
    "                    good_device_info = info\n",
    "        except Exception as e :\n",
    "            print(\"Exception:\", e)\n",
    "            \n",
    "    aud.terminate()\n",
    "    if good_device_info is None:\n",
    "        raise Exception(\"Did not find a good input device !\")\n",
    "    else:\n",
    "        return good_device_info\n",
    "\n",
    "info = pyaudio_get_output_device()\n",
    "good_idx = info['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8f5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expression 'paInvalidSampleRate' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 2048\n",
      "Expression 'PaAlsaStreamComponent_InitialConfigure( &self->playback, outParams, self->primeBuffers, hwParamsPlayback, &realSr )' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 2721\n",
      "Expression 'PaAlsaStream_Configure( stream, inputParameters, outputParameters, sampleRate, framesPerBuffer, &inputLatency, &outputLatency, &hostBufferSizeMode )' failed in 'src/hostapi/alsa/pa_linux_alsa.c', line: 2842\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -9997] Invalid sample rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maudio_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m play_audiofile\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplay_audiofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudiofile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_device_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/catkin_ws/src/nn_pipeline/audio_utils.py:32\u001b[0m, in \u001b[0;36mplay_audiofile\u001b[0;34m(audiofile, output_device_index)\u001b[0m\n\u001b[1;32m     29\u001b[0m p \u001b[38;5;241m=\u001b[39m pyaudio\u001b[38;5;241m.\u001b[39mPyAudio()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# open stream based on the wave object which has been input.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_format_from_width\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsampwidth\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetnchannels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetframerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43moutput_device_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_device_index\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# read data (based on the chunk size)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m data \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mreadframes(chunk)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyaudio/__init__.py:639\u001b[0m, in \u001b[0;36mPyAudio.open\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Opens a new stream.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    :returns: A new :py:class:`PyAudio.Stream`\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mPyAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streams\u001b[38;5;241m.\u001b[39madd(stream)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyaudio/__init__.py:441\u001b[0m, in \u001b[0;36mPyAudio.Stream.__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    438\u001b[0m     arguments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream_callback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stream_callback\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39minputLatency\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_latency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39moutputLatency\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -9997] Invalid sample rate"
     ]
    }
   ],
   "source": [
    "from audio_utils import play_audiofile\n",
    "play_audiofile(audiofile = 'output.wav', output_device_index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6546af9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/your_tts is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      "\r"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "class TextToSpeech:\n",
    "    def __init__(self):\n",
    "        # Running a multi-speaker and multi-lingual model\n",
    "\n",
    "        # List available \n",
    "        model_name = TTS.list_models()[0]\n",
    "        # Init TTS\n",
    "        self.tts = TTS(model_name, progress_bar = False, gpu = True);\n",
    "    def text_to_speech(self, text):\n",
    "        self.text_to_speech_to_file(text, output = 'tmp1.wav')\n",
    "        \n",
    "        \n",
    "    def text_to_speech_to_file(self, text, output = 'output.wav'):\n",
    "        # Run TTS\n",
    "        self.tts.tts_to_file(text=text, speaker=self.tts.speakers[4], language=self.tts.languages[0], \n",
    "                             file_path=\"output.wav\")\n",
    "        #wav = tts.tts(\"This is a test! This is also a test!!\", speaker=tts.speakers[1], language=tts.languages[0])\n",
    "        # Text to speech to a file\n",
    "        #tts.tts_to_file(text=\"Hello world!\", speaker=tts.speakers[0], language=tts.languages[0], file_path=\"output.wav\")\n",
    "txt2spch = TextToSpeech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "281fd127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['let me tell you a little something something']\n",
      " > Processing time: 0.05411958694458008\n",
      " > Real-time factor: 0.02181361827673522\n",
      "\r"
     ]
    }
   ],
   "source": [
    "txt2spch.text_to_speech_to_file(text = 'let me tell you a little something something')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b0b95",
   "metadata": {},
   "source": [
    "# ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc31b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Get a ChatGPT API which actually works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1048e3a0",
   "metadata": {},
   "source": [
    "# Streaming audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c88691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 3, 'structVersion': 2, 'name': 'Logitech USB Headset: Audio (hw:1,0)', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.008, 'defaultLowOutputLatency': 0.008, 'defaultHighInputLatency': 0.032, 'defaultHighOutputLatency': 0.032, 'defaultSampleRate': 48000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:869:(find_matching_chmap) Found no matching channel map\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KWARGS: {'format': 8, 'channels': 1, 'rate': 48000, 'input': True, 'frames_per_buffer': 960, 'stream_callback': <function Audio.__init__.<locals>.proxy_callback at 0x7f2aa00659d0>, 'input_device_index': 3}\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_route.c:869:(find_matching_chmap) Found no matching channel map\n"
     ]
    }
   ],
   "source": [
    "from audio_utils import record_clip, pyaudio_get_input_mic_device, SpeechToTextHandler\n",
    "# Get good device info\n",
    "device_info = pyaudio_get_input_mic_device()\n",
    "# Initialize VAD and stuffs\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = whisper.load_model(\"base\").to(device)\n",
    "\n",
    "Speech_to_text_obj = SpeechToTextHandler(nospinner = False, model=model, savewav = False, vad_aggressiveness=2, device = device_info['index'], rate = int(device_info['defaultSampleRate']),\n",
    "        file = 'out.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c105124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening (ctrl-C to exit)...\n",
      "I'm going to get it. Me, fail./ - \\ | / - \\ | \n",
      "I don't know nothing about this shit.\n",
      "Take me home.\n",
      "Finally!- \\ | / - \\ | / \n",
      "I don't know how to do it, but I'm going to do it.\\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \n",
      "You're on Falcon GPCA./ - \\ | / - \\ | / - \\ | / - \\ \n",
      "You're a fucking gypsy, eh? Haha, so you're just a smart, powerful, steady, detection, link, ghost-boarding, or anything? A regular? What is? A regular ghost-configured in a table, or a regular, text-marked, or a cock-me-er-lock? Cogs and pussy. / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | \n",
      "I'll see you later. | / - \\ | / - \\ | \n",
      "Cogs and Puss and Powerful stay in the rotation league goes forward. This is the Puss and Puss. Self device is CUDA. If Torch CUDA is available, L CPU. - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \n",
      "I'll be back soon.\\ | / - \\ | \n",
      "I'm gonna send you a message. Okay. | / - \\ | / - \\ | / - \\ | / - \\ \n",
      "I can see it tomorrow. See you. See you.\n",
      "Thank you.\n",
      "I can see it. I can see it. Pretty no elections with words. | / - \\ | / - \\ | / - \n",
      "Thank you.\\ | \n",
      "Pretty no ad-action with words.\n",
      "Check out the rest.\n",
      "Challenges, reward function for reinforcement learning, necessity of retraining on similar tasks, human feedback, few shots, required, few shots. \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / \n",
      "and the reward function.\n",
      "Thank you.\\ \n",
      "That's quite a good idea.\n",
      "I'm going to do it I'm going to do it I'm going to do it I'm going to do it I'm going to do it I'm going to do it I'm going to do it I'm going to do it I'm going to do it\\ | / - \\ | / - \\ \n",
      "What should I do? \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | / - \\ | \n",
      "3, 3 legs I'm going to get you a little bit further I'm going to get you a little bit further I can't help but thank you I'm going to get you a little bit further\n",
      "We easy to penetrate.\n",
      "How to do this? Easy to play. / - \\ | / - \\ | / - \\ | / - \n",
      "Thank you.\\ | / - \\ \n",
      "Thank you.\\ | \n",
      "Thank you.\\ | / - \\ | / - \\ | / \n",
      "Ta-da-da! \\ | \n",
      "Tadadadada\\ | / - \n",
      "Ta-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da\n",
      "I'm going to check on.\n",
      "- \\ | / - \\ | / - \\ | / - \\ | / \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<audio_utils.VADAudio at 0x7f2aa0036e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "Speech_to_text_obj.stream_from_mic()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d295ce94",
   "metadata": {},
   "source": [
    "Speech_to_text_obj.vad_audio.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
